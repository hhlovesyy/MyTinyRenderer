# Lesson_6 纹理映射基础

## 1.纹理坐标/UV坐标

​	在之前的文章中，我们渲染出了一些物体，这些物体具有不同的颜色，但总感觉会缺乏一些细节。在这一节中，我们会介绍”纹理“的相关知识，并将其应用在我们的模型上。读者之前可能听说过”贴图“这个概念，实际上贴图一般就是指纹理，是二维空间的一张图。为我们的模型添加纹理本质上就是把这张二维的贴图“贴”在三维的物体上，**而这个过程就被称之为“纹理映射”。**

> 在计算机图形学中，纹理是用来为三维模型表面添加细节和视觉效果的重要元素。为了将这种二维图像（纹理）正确地映射到三维物体上，我们需要使用一种称为纹理坐标的系统。这些坐标通常被称为UV坐标，其中“U”和“V”代表纹理图像中的水平和垂直轴。通过将每个顶点与相应的UV坐标关联起来，计算机能够准确地确定如何将纹理铺展到物体表面，从而实现生动且现实的视觉效果。

​	下图体现了一张纹理贴图在纹理空间（UV空间）下的UV坐标：

![image-20241011152025687](./assets/image-20241011152025687.png)

​	可以看到，U和V的范围都是[0，1]，接下来要做的事就是把这张UV图贴在物体上。以后我们统称上述图所在的空间为UV空间。值得一提的是现在常见的着色器语言（如OpenGL， DirectX，Vulkan）对于纹理坐标的起点和U轴、V轴的方向并不是统一规定的，比如说OpenGL就如上图所示，以左下角作为UV空间的起点，U轴向右，V轴向上。而在DirectX、Metal和Vulkan中则是以左上角作为UV空间的起点，U轴向右，V轴向下。在实际的开发中，我们或许需要根据不同的API来调整纹理坐标的方向，以保证纹理的正确映射。

![image-20241108102125752](Lesson_6 纹理映射基础.assets/image-20241108102125752.png)

> 一个参考：https://jdelezenne.github.io/Codex/Game/Texture.html

------



## 2.纹理映射

​	容易想到的是，我们可以为模型上的每一个点定义一个在UV空间的坐标，然后采样对应纹理的位置作为模型上这个点的颜色。事实上在类似于obj格式的文件中确实存储着每个顶点的UV坐标，例如下面是一个obj文件的一部分：

```c
vt 0.052860 0.740138  //这里的vt就记录着每个顶点的UV坐标
vt 0.073368 0.751300
vt 0.073806 0.818326
vt 0.067983 0.799840
vt 0.061847 0.779863
vt 0.167926 0.947280  
vt 0.186658 0.941543
//...
f 22255/7017/6478 22258/7020/6481 22256/7018/6479  //这里f表示一个三角形面，一共三项表示三个顶点，每个顶点的a/b/c中的b则表示纹理坐标的索引，例如7017就表示索引到id=7017的顶点的vt坐标，即为纹理采样坐标
f 22259/7021/6482 22258/7020/6481 22255/7017/6478
f 22259/7021/6482 22260/7022/6483 22258/7020/6481
f 22255/7017/6478 22257/7019/6480 22261/7023/6484
f 22259/7021/6482 22255/7017/6478 22261/7023/6484
f 22245/7007/6468 22262/7024/6485 22244/7006/6467
f 22257/7019/6480 22263/7025/6486 22261/7023/6484
```

>$f (v,vt,vn) $ ：面（顶点，纹理坐标，顶点法向量）
>
>$vt(u,v)$ ： 纹理坐标

​	在obj文件中记录了三角形顶点的UV值，而三角形中间像素的UV值可以像之前插值颜色一样，利用三角形的重心坐标进行插值（根据三个顶点在纹理坐标上的值，在纹理坐标进行重心插值）。在Github的仓库中，我们提供了一个可交互式Demo，读者可以拖动UV坐标，屏幕上会呈现出对应该点的UV坐标，并且高亮显示对应的点，读者可以很方便地跟上面的UV空间的UV图做对比，例如下面的动图：



<video src="./assets/demo_01.mp4"></video>

------



## 3.UV展开及类型

​	现在我们知道了一个模型会记录各个顶点UV坐标，以及纹理映射的概念和过程，读者可能会产生一个疑问，那就是这个UV坐标是怎么生成的？如果是简单的几何体（例如上面展示的球体），可以利用数学关系将几何映射到UV的坐标（比如球体可以将球面坐标映射到UV坐标上），但对于比较复杂的几何体，如人物、场景的模型，这个UV坐标要如何制作映射关系呢？这其实就是类似Maya，Blender等建模软件中的UV Editor的功能了，这些建模软件的UV编辑器的作用就是方便美术工作人员展开模型的UV，并且依据UV绘制对应的贴图，这样在做渲染的时候就可以把UV和贴图对应起来，达到预期的效果。我们以Maya为例，看一下UV Editor的样子：

![image-20241011171535628](./assets/image-20241011171535628.png)

​	可以看到右侧是一个稍微复杂一点的桥的模型，左面则是Maya提供的UV编辑器，这里的创建菜单栏可以帮助我们创建UV Layout，即模型顶点和UV的映射关系，如果我们点击上图的创建->自动，会得到下面的结果：

![image-20241011171703964](./assets/image-20241011171703964.png)

​	Maya会自动展开到对应的UV。左图里面的UV Editor里面的边可以对应到右图模型上的边。以上只是一个例子，真正的美术工作人员需要对展开UV进行规范化处理，例如控制每个UV壳之间的间隙，对UV占用率进行分析等，这里不再过多介绍。注意到创建菜单栏有一些不同的创建UV映射的算法，可以方便人们的编辑。

> 注：Maya等建模软件中提供对已有的UV进行切割、移动、旋转、缩放、重排、展开等操作，以方便进行自由度更高的控制。

在接下来的章节中，我们会介绍纹理的基本属性、纹理的缩放和一些特殊的纹理。

------



## 4.纹理属性

​	在前面的部分，我们介绍了纹理在图形学中的作用，以及纹理是怎样由艺术家绘制出来的。纹理有很多属性，它们会决定在不同情景下纹理的不同状态。想要学习纹理有哪些属性，最直观的方式是直接看在常见的渲染器，或者比如游戏引擎中纹理有哪些可以属性。这里以Unity为例，我们来看一下一张纹理有哪些特征：

​	在Unity中导入一张纹理，然后点击纹理，可以看到如下的界面：

![image-20241014214544898](./assets/image-20241014214544898.png)

​	可以看到，纹理的属性特别多，这里我们会介绍一些常见的纹理属性，并且对他们进行更具体的解释。读者可以对此有个大概的印象，哪个部分不了解的话可以快速跳转到对应的章节。具体介绍的内容有：

- Tiling&Offset : 指的是纹理的重复次数和偏移量；
- Texture Type：纹理的类型，例如Normal Map，Cookie，Lightmap等；
- sRGB：是否使用sRGB色彩空间，也即是否进行Gamma校正；
- Wrap Mode：纹理的重复方式，例如Repeat，Clamp等；
- Filter Mode：纹理的过滤方式，例如Point，Bilinear，Trilinear等；
- Mipmap：纹理的Mipmap，用于提高纹理的渲染效率；
- Aniso Level：各向异性过滤，用于提高纹理的渲染效果；
- Virtual Texture：虚拟纹理，用于提高纹理的渲染效率；
- Compression：纹理的压缩方式，用于减少纹理的内存占用；

------



### （1）Tiling & Offset

​	虽然在上图中没有显示这个属性，但实际上在纹理采样中tiling&offset是十分重要的参数，这里我们先介绍一下这两个属性。

​	很多时候我们要把一张纹理贴在一个模型上，但是这张纹理的大小和模型的大小并不一定是一样的，这时候我们就需要对纹理进行缩放和偏移。在纹理映射的过程中，我们可以通过Tiling & Offset来控制纹理的重复次数和偏移量。Tiling可以理解为纹理“重复”的次数，Offset表示纹理的偏移量。纹理采样结合tiling和offset之后，UV坐标会变为：

```c
vec2 uv = vUV * _MainTex_ST.xy + _MainTex_ST.zw;
```

​	其中`_MainTex_ST.xy`表示Tiling，`_MainTex_ST.zw`表示Offset，vUV则表示原来的UV值。例如在Unity中，我们可以通过在材质Material的Inspector面板来调整Tiling和Offset的值。在后面的demo演示中，我们也可以更直观地看到Tiling和Offset对纹理采样的影响。以下一组对比图分别是：

（a）默认tiling=1，offset=0（这里为了简化，tiling=tilingX=tilingY=1，offset也是同理，下同）；

（b）tiling=2，offset=0，此时视觉表现上纹理被”缩小“了；

（c）tiling=1，offset=0.2，此时视觉表现上纹理”发生了移动“；

> 注意，为了让结果比较直观，这里我们固定Wrap Mode为Repeat，读者暂时只需要关心不同Tiling和Offset对纹理采样的影响即可。

![image-20241014221822310](./assets/image-20241014221822310.png)

​	通过以上的对比图，相信读者已经对Tiling和Offset有了一定的了解，接下来我们会介绍另外一些纹理的属性。

------



### （2）Texture Type

![image-20241014221920030](./assets/image-20241014221920030.png)

​	可以看到，类似Unity的引擎支持非常多的Texture类型，并且也支持不同的Texture Shape，例如Cube，2D Array，3D等，这些在后面会进行更详细的介绍。在前面讲解的基础纹理都算是Default类型，也就是默认的纹理（一般用于做普通贴图，附着在模型上），比如前面展示的贴图类型一般是base map。后续会重点介绍的Texture类型如下，读者可以先对他们有一个基本的理解：

- Normal Map：法线贴图，用于模拟表面的凹凸感，使得模型看起来更加真实。

- Cookie：用于实现光照效果，例如在Unity中，我们可以通过Cookie来实现Spot Light的效果。

- Lightmap：用于实现光照效果，例如在Unity中，我们可以通过Lightmap来实现全局光照的效果。

- Shadowmask：用于实现阴影效果，例如在Unity中，我们可以通过Shadowmask来实现阴影的效果。

- Sprite：用于实现2D游戏中的精灵（Sprite）效果，这种效果一般用于2D游戏中，后面会介绍其原理。

------



### （3）关于sRGB

​	在前面的章节中，我们提到了纹理的颜色，但是在实际的渲染过程中，我们会遇到一个问题，就是颜色在屏幕上的显示。在计算机中，颜色的显示是通过RGB来表示的，但是在显示器上，颜色的显示是通过sRGB的颜色空间来表示的。这里深入探讨的话其实涉及到一个叫做**伽马（gamma）校正**的问题，Unity 中的 sRGB 属性主要用于指示纹理是否以 sRGB 色彩空间存储。如果纹理标记为 sRGB，Unity 会在渲染时自动对其进行 gamma 校正，以确保其显示效果符合人眼的感知。

> 简单来说，Gamma 校正是一种非线性操作，它调整图像的亮度信息，以便更好地匹配人类视觉系统的感知。由于人眼对亮度的感知并不是线性的，因此需要通过 gamma 曲线来校正图像。Gamma校正的目的是使图像在显示器上的亮度更符合人眼的感知，从而使图像看起来更加自然。在后面的章节中，我们会详细介绍Gamma校正的原理。

​	例如我们前面那张用于贴在物体表面的纹理，如果它的颜色在制作的时候是在线性色彩空间的（linear，意味着在制作的时候没有考虑gamma校正），那么在显示到屏幕上的时候为了让视觉效果更好，就可以勾选上sRGB属性。

------



### （4）Wrap Mode

​	在前面的章节中，我们提到了Tiling & Offset，这里我们再介绍一下Wrap Mode。Wrap Mode主要用于控制纹理的重复方式，例如Repeat表示纹理会重复显示，Clamp表示纹理会被截断，Mirror表示纹理会被镜像显示。从底层来看，Wrap Mode主要是针对于UV坐标不在[0,1]范围内的情况。我们将上面的Repeat，Clamp以及Mirror的Wrap Mode翻译成逻辑：

> 例如我们有一个UV坐标为(1.2, 0.5)，这时候Wrap Mode就会发挥作用，Repeat会把这个坐标映射到(0.2, 0.5)，Clamp会把这个坐标映射到(1, 0.5)，Mirror会把这个坐标映射到(0.8, 0.5)。算法如下：
> ```c
> //Repeat，假设uv坐标没有负数（简化逻辑判断）
> o.uv = frac(i.uv);  //frac：返回小数部分
> //clamp
> o.uv = clamp(i.uv, 0, 1);//clamp：截断到0-1
> //mirror
> o.uv = mod(i.uv, 2.0); // 将 UV 坐标模 2.0，得到的结果是 [0, 2.0]
> if (o.uv.x > 1.0) o.uv.x = 2.0 - o.uv.x; // 处理 X 轴反射
> if (o.uv.y > 1.0) o.uv.y = 2.0 - o.uv.y; // 处理 Y 轴反射
> ```

​	在纹理应用的时候经常会出现纹理重复的情况，这时候Wrap Mode就会发挥作用。例如我们有一张砖块的贴图，我们希望这张贴图重复显示在一个平面上，这时候我们就可以使用Repeat的Wrap Mode。下面是一个对比图，显示同样是砖块图贴在平面上，使用不同的Wrap Mode的效果（这个被贴图贴上的平面的UV坐标从左到右是[0，2]，左，中，右分别为Clamp，Repeat和Mirror）：

![image-20241015152423616](./assets/image-20241015152423616.png)

> Wrap Mode与前面讲解的Tiling&Offset之间的联系：
>
> 复习一下Tiling和Offset对UV坐标的影响：`vec2 uv = vUV * _MainTex_ST.xy + _MainTex_ST.zw;`,其中.xy记录tiling，.zw记录offset，不难看出，例如当tiling>1，offset=0的时候，就会出现UV坐标超出[0，1]的情况，这时候Wrap Mode就会发挥作用，将超出的UV坐标映射到[0，1]范围内。所以说，二者对于纹理采样的结果共同具有重要的影响。

​	常见的Wrap Mode基本就是Clamp和Repeat，Clamp主要用于一些防止计算的采样点由于浮点数精度影响超出纹理UV范围的情况（比如说后面会讲的通过光照的信息采样贴图），而Repeat则是在UV超出[0，1]范围的时候，将纹理重复显示。对于视觉上直接显示在渲染结果上的贴图（比如基础纹理贴图），一般将Wrap Mode设置为Repeat会比较稳妥一些。从上图也可以看到，Repeat的效果比较自然。

------



### （5）Filter Mode

​	这里先用最简单的语言描述一下纹理的Filter Mode指的是什么，以及应用的场合是什么，接下来就会详细介绍。

> Filter Mode主要是用于解决纹理采样的问题，例如在纹理缩放的时候（读者可以想象一下，如果我们要把一张小纹理贴在一面巨大的墙上，那么这面墙就会显得很“糊”，这就是因为我们强行放大了纹理，在给墙壁着色的时候可能会采样到纹理贴图非像素中心的位置，此时就需要进行纹理的缩放），我们需要对纹理进行过滤，这时候Filter Mode就会发挥作用。
>
> Filter Mode主要用于控制纹理的过滤方式，例如Point表示此时纹理会使用最近的像素点，Bilinear则表示纹理会使用最近的四个像素点，Trilinear表示纹理会使用最近的八个像素点。

​	算法的细节会在第5部分着重介绍。

------



## 5.纹理相关算法1——纹理的缩放

>这一节的内容比较关键，涉及到的一些概念在整个图形学中都是十分重要的，读者可以反复阅读以加深印象。

### （1）纹理的插值

​	在光栅化的部分我们有提及过，在光栅化的时候由于着色是离散的，因此在采样的时候是用每个像素的中心点来采样的。而对于纹理来说，一张图也是由这一个个像素点构成的。这就意味着如果我们要把一张小纹理贴在一面巨大的墙上，就需要强行放大纹理，在给墙壁着色的时候很可能会采样到纹理贴图非像素中心的位置，比如说UV坐标为（0.618，0.625）的点如果不在纹理图某个像素的中心，就要对其进行处理。不妨将这个问题具象化，即解决下图的问题：

![image-20241015161509845](./assets/image-20241015161509845.png)

​	其中P点是我们要求解的颜色，而A1~A4则是纹理图中像素点的中心，每个像素点的颜色是离散的，符合我们之前描述的情况。计算P点的颜色跟我们之前学的重心插值很像，只不过这里是在二维的纹理空间进行插值。在这里我们可以用最近邻插值，双线性插值，三线性插值等方法来解决这个问题。这里我们先介绍最近邻插值和双线性插值。



#### （a）最近邻插值

- **工作原理**：这种方法非常简单。当你需要在纹理上采样一个像素时，它会找到离这个位置最近的纹素（Texel），然后直接使用那个像素的颜色。
- **优点**：速度快，因为只需要查找一个像素。
- **缺点**：图像可能看起来非常颗粒（blocky）或锯齿状，尤其是在放大纹理时，因为它没有考虑周围像素的信息。

这种插值方式很符合我们直观的想法，比如P点看起来离A1点最近，那用A1直接作为P点的颜色就可以了。利用这种方法着色得到的结果实际上就如上图所示。最近邻插值的算法如下：

```python
def nearest_neighbor_sample(texture, uv, texture_width, texture_height):
    # 将 UV 坐标转换为实际的纹理坐标
    x = uv[0] * texture_width  # uv[0] 对应于 U 坐标
    y = uv[1] * texture_height  # uv[1] 对应于 V 坐标
    
    # 使用 int() 函数获取最近邻的像素坐标
    nearest_x = int(x)
    nearest_y = int(y)
    
    # 确保坐标在纹理范围内
    nearest_x = max(0, min(nearest_x, texture_width - 1))
    nearest_y = max(0, min(nearest_y, texture_height - 1))
    
    # 从纹理中获取颜色
    output_color = texture[nearest_y][nearest_x]
    
    return output_color
```

​	对本节最开始的纹理做最近邻插值，在放大10倍之后的效果如下：

<img src="./assets/image-20241015160616324.png" alt="image-20241015160616324" style="zoom:67%;" />

​	可以看到，这个效果是比较“硬”的。最近邻插值可以用在一些风格化的场景，比如像素风格的游戏，或者是一些风格化的动画中。

------



#### （b）双线性插值

- **工作原理**：双线性插值是最近邻插值的一种改进。它会考虑到周围四个像素的颜色，并根据距离加权平均这些颜色。
- **优点**：图像看起来更加平滑，因为它考虑了周围像素的信息。
- **缺点**：速度比最近邻插值慢，因为需要计算周围像素的加权平均。



##### 前置知识 ：线性插值

我们先回顾下线性插值，假设目前有$(x_0,z_0)$和$(x_1,z_1)$，我们需要计算在$x_0$和$x_1$之间的某个位置$x$的值$z$。我们可以通过线性插值来计算：

$$\frac{z-z_0}{x-x_0}=\frac{z_1-z_0}{x_1-x_0}$$

$$z=\frac{x_1-x}{x_1-x_0}z_0+\frac{x-x_0}{x_1-x_0}z_1$$

我们观察上式，实际上z等于$z_0$和$z_1$的加权平均，其中权重是$x_1-x$和$x-x_0$。

而双线性插值本身其实也就是在两个方向上做线性插值。

##### 双线性插值

我们把上述的问题抽象为下面的问题，其中Q11，Q12，Q21, Q22分别表示周围四个像素点的颜色，也即上面的A1~A4点的颜色。

<img src="./assets/1024px-BilinearInterpolationV2.svg.png" alt="undefined" style="zoom:67%;" />

​	之所以叫做双线性插值，是因为我们需要进行两次插值。先在水平方向上进行插值，首先可以计算出R2和R1的颜色，然后在垂直方向上做第二次插值，求出P的颜色。求出P点的颜色可以通过下面的公式计算：
$$
\begin{aligned}
& f\left(x, y_1\right)=\frac{x_2-x}{x_2-x_1} f\left(Q_{11}\right)+\frac{x-x_1}{x_2-x_1} f\left(Q_{21}\right) \\
& f\left(x, y_2\right)=\frac{x_2-x}{x_2-x_1} f\left(Q_{12}\right)+\frac{x-x_1}{x_2-x_1} f\left(Q_{22}\right)
\end{aligned}
$$
其中$f\left(x, y_1\right)=f(R_1)$,$f\left(x, y_2\right)=f(R_2)$。接下来我们要进行第二次插值，即沿着竖直方向：
$$
\begin{aligned}
& f(x, y)=\frac{y_2-y}{y_2-y_1} f\left(x, y_1\right)+\frac{y-y_1}{y_2-y_1} f\left(x, y_2\right) \\
& =\frac{y_2-y}{y_2-y_1}\left(\frac{x_2-x}{x_2-x_1} f\left(Q_{11}\right)+\frac{x-x_1}{x_2-x_1} f\left(Q_{21}\right)\right)+\frac{y-y_1}{y_2-y_1}\left(\frac{x_2-x}{x_2-x_1} f\left(Q_{12}\right)+\frac{x-x_1}{x_2-x_1} f\left(Q_{22}\right)\right) \\
& =\frac{1}{\left(x_2-x_1\right)\left(y_2-y_1\right)}\left(f\left(Q_{11}\right)\left(x_2-x\right)\left(y_2-y\right)+f\left(Q_{21}\right)\left(x-x_1\right)\left(y_2-y\right)+f\left(Q_{12}\right)\left(x_2-x\right)\left(y-y_1\right)+f\left(Q_{22}\right)\left(x-x_1\right)\left(y-y_1\right)\right) \\
& =\frac{1}{\left(x_2-x_1\right)\left(y_2-y_1\right)}\left[x_2-x \quad x-x_1\right]\left[\begin{array}{ll}
f\left(Q_{11}\right) & f\left(Q_{12}\right) \\
f\left(Q_{21}\right) & f\left(Q_{22}\right)
\end{array}\right]\left[\begin{array}{l}
y_2-y \\
y-y_1
\end{array}\right] .
\end{aligned}
$$
在上式推导的最后，将其转化为了矩阵乘法的形式，这样GPU在计算的时候会比较快一些。有了以上的推导之后，我们就可以来写双线性插值的代码了（为了方便理解，这里还是用正常插值的方式）：

```python
# 双线性插值的代码
def bilinear_interpolate(texture, uv):
    texture_height, texture_width, _ = texture.shape
    
    # 将 UV 坐标转换为实际的纹理坐标
    x = uv[0] * (texture_width - 1)  # u坐标，范围 [0, texture_width - 1]
    y = uv[1] * (texture_height - 1)  # v坐标，范围 [0, texture_height - 1]

    # 获取四个邻近像素的坐标
    x0 = int(x)      # 左上角像素的 x 坐标
    x1 = min(x0 + 1, texture_width - 1)  # 右上角像素的 x 坐标
    y0 = int(y)      # 左上角像素的 y 坐标
    y1 = min(y0 + 1, texture_height - 1)  # 左下角像素的 y 坐标

    # 计算四个角点的权重
    wx = x - x0  # 横向偏移量
    wy = y - y0  # 纵向偏移量

    # 获取四个角点的颜色
    c00 = texture[y0, x0]  # 左上角
    c01 = texture[y0, x1]  # 右上角
    c10 = texture[y1, x0]  # 左下角
    c11 = texture[y1, x1]  # 右下角

    # 进行双线性插值
    top = (1 - wx) * c00 + wx * c01  # 上边插值
    bottom = (1 - wx) * c10 + wx * c11  # 下边插值
    output_color = (1 - wy) * top + wy * bottom  # 最终插值

    return output_color
```

​	依旧使用本节最开始的纹理，做双线性插值，在放大10倍之后的效果如下：

<img src="./assets/image-20241015165025026.png" alt="image-20241015165025026" style="zoom:67%;" />

​	可以看到，双线性插值相当于一个“滤波”操作，让贴图变得糊一些，但同时也会更加平滑，从视觉角度更容易接受。双线性插值在很多的图形学应用中都会用到，比如在纹理的缩放，图像的缩放等方面。



#### （c）三线性插值

​	顾名思义，三线性插值需要做三次插值。显然，从性能消耗上应当是三线性插值>双线性插值>最近邻插值。从三线性插值诞生之初来看，其指的是一种在三维空间中进行插值的方法。它是双线性插值的推广，主要用于处理体数据（如三维纹理、医学图像、气象数据等）。

​	与双线性插值一样，三线性插值通过在三个维度上进行线性插值来估算一个点的值。在三维空间中，我们可以将数据视为立方体形式，也就是一个包含多个小立方体（称为体素）的网格。每个体素的角点都有一个已知的值。对于给定的某一点 ( (x, y, z) )，该点通常位于某个体素内，我们需要使用包围该点的八个顶点的值来进行插值。

​	不过其实推广来看，我们其实可以认为**三线性插值就是在双线性插值上增加了一个插值的维度**。当理解了这里面本质的思想后，就可以想到三线性插值其实不只是可以用来处理体数据。比如说我们有在时间上连续的若干帧图像，就可以用三线性插值的思想来做时间维度的插值，这样可以在一些屏幕后处理的效果或者是反走样中对结果进行平滑。

​	在下面的章节（Mipmap），我们会介绍三线性插值在Mipmap中的应用。



------



### （2）Mipmap

​	乍一看这个词语似乎没什么头绪，但实际上Mipmap是一个非常重要的概念。“MIP”来自于拉丁语 *multum in parvo* 的首字母，意思是“放置很多东西的小空间”。Mipmap是一种纹理优化技术，用于提高纹理的渲染效率。Mipmap是一个包含了多个不同分辨率的纹理的纹理集合，这些纹理是原始纹理的不同分辨率的版本。在实际应用中，我们会在加载纹理的时候生成Mipmap，然后在渲染的时候根据纹理的大小和距离来选择合适的Mipmap级别。不妨先来看一下没有Mipmap技术会产生什么问题（下图纹理滤波采用双线性插值，Wrap Mode是Repeat模式）：

<video src="./assets/Mipmap.mp4"></video>

​	可以看到，没有Mipmap技术的时候，离近了还好一些，但纹理在比较远处的时候会出现很多的锯齿，而且随着镜头的移动会出现闪烁的现象，很影响视觉上的观感。这是因为在距离较远的时候，很有可能屏幕空间上一个像素对应的纹理空间上的多个像素，更极端的情况，假设我们要渲染的这个平面非常远，很可能一整张纹理附着的平面在视觉上只占据一个像素（甚至不到一个像素），那么究竟要用纹理上什么样的像素值作为屏幕渲染时的着色值呢？这就是Mipmap技术要解决的问题。

> Mipmap技术主要用来解决以下问题：
>
> - **纹理采样伪影**：在渲染远距离物体时，使用高分辨率纹理可能导致模糊和锯齿状边缘等视觉伪影。并且在远离摄像机的情况下，物体表面只占用屏幕上的少量像素，但仍然使用完整的高分辨率纹理进行采样，导致不必要的性能消耗。

​	接下来我们以一个更详细的例子入手，并以此为契机，介绍mipmap的原理和使用后的效果。假设你正在玩一个打靶游戏，靶子是一个正方体。在为这个靶子制作纹理的时候，制作者们按照`400*400`的分辨率制作了相关的纹理贴图。我们假设在你距离这个靶子5米的时候，这张贴图在屏幕上的渲染结果正好也是`400*400`的分辨率，皆大欢喜。但假设我们现在不断往后移动，当移动到某个点的时候，整个靶子渲染在屏幕上只能占据`200*200`的分辨率了（想象一下这个场景，你不断后退，靶子也越来越小），这时我们要解决的问题就是把`400*400`分辨率的纹理图缩小到`200*200`。

​	这时问题就来了，相当于此时一个屏幕上的像素对应原来纹理图上的四个像素，那么具体采样哪个点的颜色作为最终渲染结果呢？可以类比想到我们前面所讲述的最近邻插值和双线性插值，我们可以把这时`200*200`的纹理A重新放大到`400*400`的纹理B，这时A每个像素中心变换后的A'就很有可能对应到B的非像素中心上，再用前面讲的最近邻插值或双线性插值求出A‘的颜色，作为A的结果。不过这样治标不治本，进一步地，我们思考一个更为极端的情况，如果我们现在距离靶子非常遥远，导致整个靶子只会被渲染到屏幕的**一个像素点**上，这时我们的一个像素点又要从`400*400`分辨率的贴图的什么位置去采样呢？

​	读者可能想到了，将一个像素点的着色结果对应到`400*400`分辨率的贴图的”某个点“上并不是一个好主意，那么如果是将这张`400*400`分辨率的贴图的所有像素取一个平均颜色作为着色结果是不是会好一些呢？**这就是Mipmap的基本思想了。**我们可以简单理解成当距离较远时，可以将原来的贴图做了一步”模糊“操作，在采样的时候就是取采样”某个范围内“的平均值，这样视觉效果会好很多。而Mipmap做的事情就是提前做一个预计算，使得我们可以做快速的、近似的范围查询，也就是查询”某个范围内“的平均值。如下图所示：

![image-20241104163742257](./assets/image-20241104163742257.png)

​	蓝色的点是本来的思路（采样某个位置），而紫色的区域则是Mipmap的思想，做范围的像素查询，以平均值作为着色结果，效果更好。

> 有一个常见的疑问是，为什么不在着色的时候直接找到渲染结果屏幕上的像素对应的贴图范围，直接对范围内的像素求平均值作为结果，而是去做一个预计算呢？**其实这就是图形学中常见的trade-off(平衡)了，如果实时去做这件事是没问题的，但会降低运行的效率，而预计算好的话会大大提高渲染的效率，但需要用额外的内存空间存储预计算的结果，是一种典型的拿空间换时间的策略。在后面的课程中，我们会看到越来越多的拿空间换时间的例子，以极致地提高渲染的性能，从而实现更酷的图形学效果。**

​	接下来，我们来看一下Mipmap是怎么预计算的。



#### （a）Mipmap的生成过程

​	如前面所说，Mipmap是对贴图进行预计算处理，以方便后续的快速范围查询操作。因此，Mipmap**简单来说就是一系列的纹理图像，后一个纹理图像是对前一个的每四个像素的求平均。**我们直接来看一组Mipmap：

​										![undefined](./assets/MipMap_Example_STS101.jpg)

​	例如在Unity中，如果对导入的纹理贴图勾选”generate mipmaps“（如下图），引擎就会自动帮我们生成每个层级的mipmap：

![image-20241015165744600](./assets/image-20241015165744600.png)

​	假设我们的纹理分辨率是256x256像素的话,它的mipmap一共就会有8个层级。每个层级是上一个层级的1/4，也就是上图的八个Mipmap层级的分辨率分别是128x128，64x64，32x32，16x16，8x8，4x4，2x2和1x1。Mipmap现在由硬件GPU帮助我们完成运算，因此计算的效率是非常高的。现在知道了Mipmap是如何产生的，问题只剩下了一个：**如何在实时渲染的时候知道要采样哪层Mipmap呢？**

> 补充：Mipmap究竟带来了多少额外的内存开销？答案是1/3左右，因为每层都是上一层的1/4，计算所有层的总开销的时候就可以用等比数列的求和公式，读者可以自己算一下，使用Mipmap之后，占用的内存是原来的4/3，即多了1/3的内存消耗。



#### （b）对Mipmap的采样

​	按照前面的学习，容易想到纹理”缩小的越厉害“，我们要采样的Mipmap层级就越大。这里诞生了三个问题：

- （1）具体在数学上如何表示这个对应关系呢？即如何决定采样哪一级的Mipmap？
- （2）如果计算的Mipmap层级不是整数，比如计算结果是2.3，要怎么采样呢？
- （3）如果我要查询的范围并不是正方形，而是一个细长条的矩形，甚至是一个倾斜的矩形，Mipmap是不是就做不好了呢？

​	Mipmap的采样过程，可以看下图更加清晰：

![image-20241104164020702](./assets/image-20241104164020702.png)

​	左侧是屏幕空间的要渲染的像素点，对应到右侧在UV空间的区域范围。而我们只要能快速计算右侧Texture Space上的范围内像素平均值，就可以作为结果返回了。从上图也可以看出，针对提出的问题（3），Mipmap确实做不好，因为在生成Mipmap的时候我们只做了每四个像素取一次平均，也就是只能处理方形区域，针对上图右侧这些细长条的矩形，或者是斜着的四边形，效果是不够好的。在后面我们会提到**各向异性过滤**的方法，可以有效改进这个问题，但现在我们先聚焦于问题（1）（2）。

​	首先针对问题1，看下面一张图：

![image-20241104165216887](./assets/image-20241104165216887.png)

​	这里的$D$就是计算要采样的Mipmap层级的值。在左图当中，$(u, v)_{00}$是当前要被着色的像素，而$(u, v)_{10}$是其右边的像素，$(u, v)_{01}$是其上边的像素。左侧图中以当前像素为左下角的四个像素采样点对应右图UV空间的四个红色的采样点。按照右图的公式我们可以求出$L$值，这个值近似可以表示“左侧屏幕空间1个像素的边长在右侧UV空间占据的长度范围”。不妨验证一下，当$L=2$的时候，说明屏幕空间一个像素差对应UV 图上的2个像素差，此时屏幕空间一个像素相当于UV图上的四个像素，对应$D=log_2L=1$，因此我们采样Mipmap的第一个层级，与前面的Mipmap的规则相符合。读者可以自行验证例如$L=4,L=8$的情况。找到了要采样的Mipmap层级，采样的UV坐标自然就是当前要着色的像素映射在UV空间的UV值了，如果采样点并不在Mipmap对应层的某个像素中心，就可以用之前讲的最近邻插值或双线性插值做滤波处理。

​	不过此时就引入了第二个问题，那就是如果计算出的$D$并不是整数，而是类似2.3这样的小数怎么办？在前面我们介绍了**三线性插值**，这里就派上了用场。例如我们计算出的$D=x$（$x$可能是一个小数），我们就可以依据下面的代码计算出要插值的两层Mipmap是什么：

```c++
low = floor(x);
high = ceil(x);
delta = x - low;
```

​	例如x=2.3，那么low=2，high=3，delta=0.3。接下来我们利用UV坐标（这里指的是UV空间里的UV坐标）对两层Mipmap采样，并采样得到对应的结果：

```c++
float2 uv = input.uv; //uv坐标
float4 col1 = tex2D(mainTex_sampler, uv, low); //对纹理贴图的第low层mipmap依据uv值进行采样,依据UV坐标可能需要最近邻插值或双线性插值，下一句类似
float4 col2 = tex2D(mainTex_sampler, uv, high); 
float4 finalCol = lerp(col1, col2, delta); //对两个颜色的采样结果进行再次插值
```

​	整个过程还是比较直观的。不难发现，在做col1和col2计算的时候，难免要用到插值操作（比如双线性插值），而在计算finalCol的时候又进行了一次插值，并且这几次插值都是线性的。**这就是三线性插值的一种应用。**是不是还是蛮直观的？

​	开启了Mipmap前后的对比如下图：

![image-20241104172416769](./assets/image-20241104172416769.png)

​	打开了Mipmap之后的效果是有不小的提升的。虽然贴图整体看上图“糊”了一点，但视觉效果基本是可以接受的。



### （3）各向异性过滤

​	各向异性过滤是为了解决上述第（3）个问题而产生的。

![image-20241104164020702](./assets/image-20241104164020702.png)

​	回顾一下上图，左侧屏幕空间的单个要着色的像素可以对应到纹理空间的细长条矩形，甚至是斜向的四边形。按照之前讲的Mipmap算法对这种场景的处理不够好，而各向异性过滤简单来说，就是在原来生成Mipmap的算法和查询Mipmap的算法的基础上，引入了长宽不相等的情况的讨论。先看下图生成普通Mipmap和采用各向异性过滤的对比：

![image-20241104173315780](./assets/image-20241104173315780.png)

​	直观来看，使用各向异性过滤会存储这些长宽不等的缩放比例，但也引入了更多的内存占用空间。生成的逻辑很好理解，就是在Mipmap的基础上加入了一些长宽不等的下采样过程。不过各向异性生成的贴图在采样的时候的逻辑会更复杂一些，在这里就不过多展开了，感兴趣的读者可以参考维基百科上的更多细节：https://en.wikipedia.org/wiki/Anisotropic_filtering，基本原理与Mipmap是一致的。

​	来看一下各向异性过滤的效果，左侧的Trilinear指的就是上一节Mipmap的结果，右侧则是采用各向异性过滤之后的效果，画质得到了更好的提升：

![undefined](./assets/Anisotropic_filtering_en.png)



## 6.本节可以学习的额外参考资料

【1】读者可能发现了，各向异性过滤在一定程度上解决了细长条的范围查询问题，但还是没有很好地解决斜向的四边形的范围查询问题。一个方案是EWA filtering，论文地址：https://www.cs.umd.edu/~zwicker/publications/EWASplatting-TVCG02.pdf。不过这种算法目前还没有在工业界得到广泛应用，大概是因为性能的问题。



在后续的补充材料中，我们会介绍几种比较重要的纹理贴图以及它们的原理，和在渲染中的应用。主要介绍的贴图类型是Environment map，Normal map，Ambient Occlusion map。
